#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TradingAgents-MCPmode Webå‰ç«¯ - è¶…ç®€åŒ–ç‰ˆæœ¬
åˆ é™¤äº†æœ‰é—®é¢˜çš„æ‘˜è¦å±•å¼€åŠŸèƒ½å’Œé«˜çº§é…ç½®æ¨¡å—
"""

import streamlit as st
import sys
import os
import asyncio
import threading
import time
import json
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥æ ·å¼åŠ è½½å™¨
try:
    from src.web.css_loader import load_financial_css, inject_custom_html, create_header_html
except ImportError as e:
    st.error(f"æ— æ³•å¯¼å…¥CSSæ ·å¼æ¨¡å—: {e}")

# å¯¼å…¥å·¥ä½œæµç¨‹ç¼–æ’å™¨
try:
    from src.workflow_orchestrator import WorkflowOrchestrator
except ImportError as e:
    WorkflowOrchestrator = None
    st.error(f"æ— æ³•å¯¼å…¥WorkflowOrchestrator: {e}")

# å¯¼å…¥å¯¼å‡ºå·¥å…·
try:
    from src.dumptools.json_to_markdown import JSONToMarkdownConverter
    from src.dumptools.md2pdf import MarkdownToPDFConverter 
    from src.dumptools.md2docx import MarkdownToDocxConverter
except ImportError as e:
    st.error(f"æ— æ³•å¯¼å…¥å¯¼å‡ºå·¥å…·: {e}")
    JSONToMarkdownConverter = None
    MarkdownToPDFConverter = None
    MarkdownToDocxConverter = None

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AIå®éªŒå®¤ - TradingAgents",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# éšè—Streamlitè­¦å‘Šä¿¡æ¯
import warnings
warnings.filterwarnings("ignore")

# éšè—æ§åˆ¶å°æ—¥å¿—
import logging
logging.getLogger().setLevel(logging.ERROR)

# éšè—Streamlitçš„ä¸€äº›UIå…ƒç´ 
try:
    st.set_option('client.showErrorDetails', False)
    st.set_option('client.toolbarMode', 'minimal')
except:
    pass

# æ·»åŠ CSSéšè—ä¸éœ€è¦çš„å…ƒç´ 
st.markdown("""
<style>
/* éšè—æˆåŠŸæç¤ºæ¡† */
.stAlert[data-testid="stAlertContainer"] {
    display: none !important;
}

/* éšè—è­¦å‘Šæç¤ºæ¡† */
.stAlert {
    display: none !important;
}

/* éšè—æ‰€æœ‰é€šçŸ¥ */
[data-baseweb="notification"] {
    display: none !important;
}

/* éšè—Streamlitçš„é»˜è®¤è­¦å‘Š */
.stException {
    display: none !important;
}
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "orchestrator" not in st.session_state:
    st.session_state.orchestrator = None
if "analysis_running" not in st.session_state:
    st.session_state.analysis_running = False
if "selected_session_file" not in st.session_state:
    st.session_state.selected_session_file = None
if "current_session_data" not in st.session_state:
    st.session_state.current_session_data = None
if "analysis_completed" not in st.session_state:
    st.session_state.analysis_completed = False


def load_page_styles():
    """åŠ è½½é¡µé¢æ ·å¼"""
    try:
        load_financial_css()
        inject_custom_html()
    except:
        pass


@st.cache_data(ttl=5)
def get_session_files_list():
    """è·å–ä¼šè¯æ–‡ä»¶åˆ—è¡¨"""
    try:
        dump_dir = Path("src/dump")
        if not dump_dir.exists():
            return []
        return sorted(dump_dir.glob("session_*.json"), key=lambda f: f.stat().st_mtime, reverse=True)
    except:
        return []


def get_agent_display_name(agent_name):
    """è·å–æ™ºèƒ½ä½“æ˜¾ç¤ºåç§°"""
    name_mapping = {
        'company_overview_analyst': 'ğŸ¢ å…¬å¸æ¦‚è¿°åˆ†æå¸ˆ',
        'market_analyst': 'ğŸ“ˆ å¸‚åœºåˆ†æå¸ˆ',
        'sentiment_analyst': 'ğŸ˜Š æƒ…ç»ªåˆ†æå¸ˆ',
        'news_analyst': 'ğŸ“° æ–°é—»åˆ†æå¸ˆ',
        'fundamentals_analyst': 'ğŸ“‹ åŸºæœ¬é¢åˆ†æå¸ˆ',
        'shareholder_analyst': 'ğŸ‘¥ è‚¡ä¸œåˆ†æå¸ˆ',
        'product_analyst': 'ğŸ­ äº§å“åˆ†æå¸ˆ',
        'bull_researcher': 'ğŸ‚ çœ‹æ¶¨ç ”ç©¶å‘˜',
        'bear_researcher': 'ğŸ» çœ‹è·Œç ”ç©¶å‘˜',
        'research_manager': 'ğŸ‘” ç ”ç©¶ç»ç†',
        'trader': 'ğŸ’¼ äº¤æ˜“å‘˜',
        'aggressive_risk_analyst': 'âš¡ æ¿€è¿›é£é™©åˆ†æå¸ˆ',
        'safe_risk_analyst': 'ğŸ›¡ï¸ ä¿å®ˆé£é™©åˆ†æå¸ˆ',
        'neutral_risk_analyst': 'âš–ï¸ ä¸­æ€§é£é™©åˆ†æå¸ˆ',
        'risk_manager': 'ğŸ¯ é£é™©ç»ç†'
    }
    return name_mapping.get(agent_name, agent_name)


def connect_orchestrator():
    """è¿æ¥WorkflowOrchestrator"""
    if WorkflowOrchestrator is None:
        return False
    
    try:
        load_dotenv()
        orchestrator = WorkflowOrchestrator()
        st.session_state.orchestrator = orchestrator
        return True
    except Exception as e:
        print(f"è¿æ¥å¤±è´¥: {e}")  # åªåœ¨æ§åˆ¶å°è¾“å‡ºï¼Œä¸åœ¨å‰ç«¯æ˜¾ç¤º
        return False


def disconnect_orchestrator():
    """æ–­å¼€WorkflowOrchestratorè¿æ¥"""
    if st.session_state.get('orchestrator'):
        st.session_state.orchestrator = None
        st.success("âœ… ç³»ç»Ÿå·²æ–­å¼€è¿æ¥")


def show_real_time_analysis():
    """å®æ—¶åˆ†ææ¨¡å— - è‡ªåŠ¨è¿æ¥ç‰ˆæœ¬"""
    if WorkflowOrchestrator is None:
        st.error("ğŸ˜± æ— æ³•åŠ è½½WorkflowOrchestratorï¼Œè¯·æ£€æŸ¥åç«¯é…ç½®")
        return
    
    # è‡ªåŠ¨è¿æ¥ç³»ç»Ÿï¼ˆå¦‚æœæœªè¿æ¥ï¼‰
    if not st.session_state.get('orchestrator'):
        if connect_orchestrator():
            st.session_state.auto_connected = True
    
    # ç®€åŒ–çš„è¾“å…¥å’Œæ§åˆ¶
    query = st.text_input(
        "è¾“å…¥æŸ¥è¯¢",
        placeholder="ä¾‹å¦‚ï¼šç»™æˆ‘åˆ†æä¸€ä¸‹600833å§",
        key="analysis_query_simple"
    )
    
    # ç®€åŒ–çš„æŒ‰é’®å¸ƒå±€ - åªæ˜¾ç¤ºå¼€å§‹/åœæ­¢
    btn_col1, btn_col2 = st.columns(2)
    
    with btn_col1:
        if st.session_state.analysis_running:
            if st.button("â¹ï¸ åœæ­¢åˆ†æ", use_container_width=True):
                stop_analysis()
        else:
            orchestrator_connected = st.session_state.get('orchestrator') is not None
            analysis_disabled = not query or not orchestrator_connected
            if st.button("ğŸš€ å¼€å§‹åˆ†æ", disabled=analysis_disabled, use_container_width=True):
                if query:
                    start_analysis(query)
    
    with btn_col2:
        # ç®€åŒ–çš„è¿›åº¦æ˜¾ç¤º
        if st.session_state.get('analysis_running') or st.session_state.get('analysis_completed'):
            progress_data = get_real_analysis_progress()
            if progress_data:
                progress = progress_data['progress']
                st.progress(progress / 100.0)
                st.caption(f"{progress_data['status']} ({progress_data['completed_agents']}/15)")
        else:
            # æ˜¾ç¤ºè¿æ¥çŠ¶æ€
            if st.session_state.get('orchestrator'):
                st.success("ğŸŸ¢ ç³»ç»Ÿå·²å°±ç»ª")
            else:
                st.error("ğŸ”´ ç³»ç»Ÿæœªè¿æ¥")
    
    # å®Œæˆæç¤º
    if st.session_state.analysis_completed:
        st.success("âœ… åˆ†æå®Œæˆï¼è¯·æŸ¥çœ‹ä¸‹æ–¹ç»“æœã€‚")


def show_history_management():
    """å†å²ä¼šè¯ç®¡ç† - è¶…ç®€åŒ–ç‰ˆæœ¬"""
    # è·å–æ‰€æœ‰JSONæ–‡ä»¶
    json_files = get_session_files_list()
    if not json_files:
        st.info("ğŸ“­ æš‚æ— å†å²åˆ†ææ•°æ®")
        return
    
    # ç®€åŒ–çš„æ–‡ä»¶é€‰æ‹©
    file_options = []
    for json_file in json_files:
        file_time = datetime.fromtimestamp(json_file.stat().st_mtime)
        display_name = f"{json_file.name} ({file_time.strftime('%m-%d %H:%M')})"
        file_options.append(display_name)
    
    # è®°å¿†é€‰ä¸­é¡¹ç´¢å¼•
    if "history_selected_index" not in st.session_state:
        st.session_state.history_selected_index = 0
    
    def on_session_change():
        """ä¼šè¯é€‰æ‹©å˜åŒ–æ—¶è‡ªåŠ¨åŠ è½½"""
        selected_idx = st.session_state.history_selector_simple
        if selected_idx < len(json_files):
            selected_file = str(json_files[selected_idx])
            load_session_data(selected_file)
            st.session_state.history_selected_index = selected_idx
    
    selected_index = st.selectbox(
        "é€‰æ‹©å†å²ä¼šè¯",
        range(len(file_options)),
        index=min(st.session_state.history_selected_index, len(file_options) - 1),
        format_func=lambda i: file_options[i],
        key="history_selector_simple",
        on_change=on_session_change
    )
    
    # é™é»˜åŠ è½½ä¼šè¯ä¿¡æ¯ï¼Œä¸æ˜¾ç¤ºæç¤º
    if st.session_state.current_session_data:
        # é™é»˜å¤„ç†ï¼Œä¸æ˜¾ç¤ºä»»ä½•æç¤º
        pass


def show_export_options():
    """å¯¼å‡ºé€‰é¡¹ - è¶…ç®€åŒ–ç‰ˆæœ¬"""
    if not st.session_state.current_session_data or not st.session_state.selected_session_file:
        st.info("è¯·å…ˆåŠ è½½ä¼šè¯æ•°æ®")
        return
    
    # ç®€åŒ–çš„å¯¼å‡ºæŒ‰é’®
    export_col1, export_col2, export_col3 = st.columns(3)
    
    with export_col1:
        if st.button("ğŸ“„ å¯¼å‡ºMD", key="export_md_simple"):
            export_to_markdown()
    
    with export_col2:
        if st.button("ğŸ“„ å¯¼å‡ºPDF", key="export_pdf_simple"):
            export_to_pdf()
    
    with export_col3:
        if st.button("ğŸ“„ å¯¼å‡ºWord", key="export_word_simple"):
            export_to_docx()


def show_analysis_results():
    """åˆ†æç»“æœå±•ç¤º - ç®€åŒ–ç‰ˆæœ¬"""
    if not st.session_state.current_session_data:
        st.info("è¯·å…ˆè¿è¡Œåˆ†ææˆ–åŠ è½½å†å²ä¼šè¯æŸ¥çœ‹ç»“æœ")
        return
    
    data = st.session_state.current_session_data
    
    # æ˜¾ç¤ºä¼šè¯åŸºæœ¬ä¿¡æ¯
    info_col1, info_col2, info_col3 = st.columns(3)
    with info_col1:
        st.metric("ä¼šè¯ID", data.get('session_id', 'N/A')[:8] + "...")
    with info_col2:
        st.metric("çŠ¶æ€", data.get('status', 'N/A'))
    with info_col3:
        completed_agents = len([agent for agent in data.get('agents', []) if agent.get('status') == 'completed'])
        st.metric("å®Œæˆæ™ºèƒ½ä½“", f"{completed_agents}/{len(data.get('agents', []))}")
    
    # æ˜¾ç¤ºç”¨æˆ·æŸ¥è¯¢
    if data.get('user_query'):
        st.markdown("**ğŸ” åˆ†ææŸ¥è¯¢:**")
        st.info(data['user_query'])
    
    # æ™ºèƒ½ä½“ç»“æœæ ‡ç­¾é¡µ
    if data.get('agents'):
        completed_agents = [agent for agent in data['agents'] if agent.get('status') == 'completed']
        
        if completed_agents:
            # æŒ‰æ™ºèƒ½ä½“ç±»å‹åˆ†ç»„
            agent_groups = {
                "ğŸ“Š åˆ†æå¸ˆå›¢é˜Ÿ": ['company_overview_analyst', 'market_analyst', 'sentiment_analyst', 
                            'news_analyst', 'fundamentals_analyst', 'shareholder_analyst', 'product_analyst'],
                "ğŸ”„ çœ‹æ¶¨çœ‹è·Œè¾©è®º": ['bull_researcher', 'bear_researcher'],
                "ğŸ‘” ç ”ç©¶ä¸äº¤æ˜“": ['research_manager', 'trader'],
                "âš–ï¸ é£é™©ç®¡ç†": ['aggressive_risk_analyst', 'safe_risk_analyst', 'neutral_risk_analyst', 'risk_manager']
            }
            
            group_tabs = st.tabs(list(agent_groups.keys()))
            
            for tab_idx, (group_name, agent_names) in enumerate(agent_groups.items()):
                with group_tabs[tab_idx]:
                    group_agents = [agent for agent in completed_agents if agent.get('agent_name') in agent_names]
                    
                    if group_agents:
                        for agent in group_agents:
                            show_agent_result(agent)
                    else:
                        st.info(f"{group_name.split(' ', 1)[1]}æš‚æ— å®Œæˆçš„åˆ†æç»“æœ")
        else:
            st.info("è¯¥ä¼šè¯ä¸­æš‚æ— å®Œæˆçš„æ™ºèƒ½ä½“åˆ†æç»“æœ")
    else:
        st.info("è¯¥ä¼šè¯ä¸­æš‚æ— æ™ºèƒ½ä½“æ•°æ®")


def show_agent_result(agent: Dict[str, Any]):
    """æ˜¾ç¤ºå•ä¸ªæ™ºèƒ½ä½“ç»“æœ - ç®€æ´ç›´æ¥æ¨¡å¼ï¼Œä¸æå¤æ‚çš„æ‘˜è¦å±•å¼€"""
    agent_name = agent.get('agent_name', 'Unknown')
    display_name = get_agent_display_name(agent_name)
    result_content = agent.get('result', '')
    
    if not result_content:
        with st.expander(display_name, expanded=False):
            st.info("è¯¥æ™ºèƒ½ä½“æš‚æ— åˆ†æç»“æœ")
        return
    
    # ç›´æ¥æ˜¾ç¤ºå®Œæ•´å†…å®¹ï¼Œåˆ é™¤æœ‰é—®é¢˜çš„æ‘˜è¦å±•å¼€åŠŸèƒ½
    with st.expander(display_name, expanded=False):
        st.markdown(result_content)


# å¯¼å‡ºåŠŸèƒ½
def export_to_markdown():
    """å¯¼å‡ºMarkdown"""
    if not JSONToMarkdownConverter:
        st.error("âŒ Markdownå¯¼å‡ºå™¨ä¸å¯ç”¨")
        return
    
    try:
        converter = JSONToMarkdownConverter("src/dump")
        result = converter.convert_json_to_markdown(st.session_state.selected_session_file)
        if result and os.path.exists(result):
            st.success(f"âœ… Markdownå¯¼å‡ºæˆåŠŸ: {result}")
            
            # æä¾›ä¸‹è½½é“¾æ¥
            with open(result, 'r', encoding='utf-8') as f:
                content = f.read()
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½Markdownæ–‡ä»¶",
                data=content,
                file_name=f"{Path(result).name}",
                mime="text/markdown"
            )
        else:
            st.error("âŒ Markdownå¯¼å‡ºå¤±è´¥")
    except Exception as e:
        st.error(f"âŒ å¯¼å‡ºé”™è¯¯: {str(e)}")


def export_to_pdf():
    """å¯¼å‡ºPDF"""
    if not MarkdownToPDFConverter:
        st.error("âŒ PDFå¯¼å‡ºå™¨ä¸å¯ç”¨")
        return
    
    try:
        converter = MarkdownToPDFConverter("src/dump")
        result = converter.convert_json_to_pdf_via_markdown(st.session_state.selected_session_file)
        if result and os.path.exists(result):
            st.success(f"âœ… PDFå¯¼å‡ºæˆåŠŸ: {result}")
            
            # æä¾›ä¸‹è½½é“¾æ¥
            with open(result, 'rb') as f:
                content = f.read()
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½PDFæ–‡ä»¶",
                data=content,
                file_name=f"{Path(result).name}",
                mime="application/pdf"
            )
        else:
            st.error("âŒ PDFå¯¼å‡ºå¤±è´¥")
    except Exception as e:
        st.error(f"âŒ PDFå¯¼å‡ºé”™è¯¯: {str(e)}")


def export_to_docx():
    """å¯¼å‡ºWordæ–‡æ¡£"""
    if not MarkdownToDocxConverter:
        st.error("âŒ DOCXå¯¼å‡ºå™¨ä¸å¯ç”¨")
        return
    
    try:
        converter = MarkdownToDocxConverter("src/dump")
        result = converter.convert_json_to_docx_via_markdown(st.session_state.selected_session_file)
        if result and os.path.exists(result):
            st.success(f"âœ… DOCXå¯¼å‡ºæˆåŠŸ: {result}")
            
            # æä¾›ä¸‹è½½é“¾æ¥
            with open(result, 'rb') as f:
                content = f.read()
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½Wordæ–‡ä»¶",
                data=content,
                file_name=f"{Path(result).name}",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
        else:
            st.error("âŒ DOCXå¯¼å‡ºå¤±è´¥")
    except Exception as e:
        st.error(f"âŒ DOCXå¯¼å‡ºé”™è¯¯: {str(e)}")


def load_session_data(json_file_path: str):
    """åŠ è½½ä¼šè¯æ•°æ®"""
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            session_data = json.load(f)
        st.session_state.selected_session_file = json_file_path
        st.session_state.current_session_data = session_data
        # é™é»˜åŠ è½½ï¼Œä¸æ˜¾ç¤ºä»»ä½•æç¤ºï¼Œä¸è°ƒç”¨st.rerun()
    except Exception as e:
        # é™é»˜å¤„ç†é”™è¯¯ï¼Œä¸åœ¨å‰ç«¯æ˜¾ç¤º
        print(f"åŠ è½½å¤±è´¥: {str(e)}")


@st.cache_data(ttl=2)
def get_real_analysis_progress():
    """ä»çœŸå®çš„ä¼šè¯JSONæ–‡ä»¶è·å–è¿›åº¦"""
    try:
        dump_dir = Path("src/dump")
        if not dump_dir.exists():
            return None
            
        # æŸ¥æ‰¾æœ€æ–°çš„ä¼šè¯æ–‡ä»¶
        session_files = list(dump_dir.glob("session_*.json"))
        if not session_files:
            return None
            
        latest_session = max(session_files, key=lambda f: f.stat().st_mtime)
        
        # è§£æä¼šè¯è¿›åº¦
        with open(latest_session, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        agents = data.get('agents', [])
        total_agents = 15  # æ€»å…±15ä¸ªæ™ºèƒ½ä½“
        completed_agents = len([a for a in agents if a.get('status') == 'completed'])
        
        progress = (completed_agents / total_agents) * 100 if total_agents > 0 else 0
        
        # ç”ŸæˆçŠ¶æ€æè¿°
        if data.get('status') == 'completed':
            status = "åˆ†æå®Œæˆ"
        elif data.get('status') == 'cancelled':
            status = "åˆ†æå·²å–æ¶ˆ"
        elif completed_agents == 0:
            status = "æ­£åœ¨åˆå§‹åŒ–..."
        else:
            running_agent = next((a for a in agents if a.get('status') == 'running'), None)
            if running_agent:
                agent_name = running_agent.get('agent_name', 'æœªçŸ¥æ™ºèƒ½ä½“')
                display_name = get_agent_display_name(agent_name)
                status = f"æ­£åœ¨æ‰§è¡Œ: {display_name}"
            else:
                status = f"å·²å®Œæˆ {completed_agents} ä¸ªæ™ºèƒ½ä½“"
        
        return {
            'progress': progress,
            'status': status,
            'completed_agents': completed_agents,
            'total_agents': total_agents,
            'session_file': str(latest_session)
        }
        
    except Exception as e:
        return None


def start_analysis(query: str):
    """å¼€å§‹åˆ†æ"""
    # æ£€æŸ¥è¿æ¥çŠ¶æ€
    if not st.session_state.get('orchestrator'):
        st.error("ç³»ç»Ÿæœªè¿æ¥ï¼Œæ— æ³•å¼€å§‹åˆ†æ")
        return
    
    # é‡ç½®çŠ¶æ€
    st.session_state.analysis_running = True
    st.session_state.analysis_completed = False
    st.session_state.analysis_cancelled = False
    
    # å°†orchestratorä¼ é€’ç»™åˆ†æå‡½æ•°
    run_analysis_sync(query, st.session_state.orchestrator)


def run_analysis_sync(query: str, orchestrator):
    """åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œåˆ†æï¼Œé¿å…é˜»å¡Streamlitä¸»çº¿ç¨‹"""
    import threading
    
    class AnalysisState:
        def __init__(self):
            self.cancelled = False
            self.running = True
            self.completed = False
            self.result = None
            self.error = None
    
    # åˆ›å»ºçŠ¶æ€å¯¹è±¡
    analysis_state = AnalysisState()
    
    def run_analysis_thread():
        """åå°çº¿ç¨‹æ‰§è¡Œåˆ†æ"""
        try:
            load_dotenv()
            
            # æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if analysis_state.cancelled:
                analysis_state.running = False
                return
            
            # åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                result = loop.run_until_complete(run_single_analysis_async_safe(query, orchestrator, analysis_state))
                
                # å†æ¬¡æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
                if analysis_state.cancelled:
                    analysis_state.running = False
                    return
                
                # åˆ†ææˆåŠŸ
                analysis_state.result = result
                analysis_state.completed = True
                analysis_state.running = False
                
            finally:
                loop.close()
                
        except Exception as e:
            # æ£€æŸ¥æ˜¯å¦æ˜¯å–æ¶ˆå¯¼è‡´çš„å¼‚å¸¸
            if not analysis_state.cancelled:
                error_msg = str(e)
                analysis_state.error = error_msg
            analysis_state.running = False
            analysis_state.completed = False
    
    # å¯åŠ¨åå°çº¿ç¨‹
    thread = threading.Thread(target=run_analysis_thread, daemon=True)
    thread.start()
    
    # å­˜å‚¨çº¿ç¨‹å¼•ç”¨å’ŒçŠ¶æ€å¯¹è±¡
    st.session_state.analysis_thread = thread
    st.session_state.analysis_state_obj = analysis_state


async def run_single_analysis_async_safe(user_query: str, orchestrator, analysis_state) -> Optional[dict]:
    """å®‰å…¨çš„å¼‚æ­¥åˆ†æå‡½æ•°"""
    try:
        # æ£€æŸ¥å–æ¶ˆçŠ¶æ€
        if analysis_state.cancelled:
            return None
            
        workflow_info = orchestrator.get_workflow_info()
        enabled_agents = orchestrator.get_enabled_agents()
        
        # æ£€æŸ¥å–æ¶ˆçŠ¶æ€
        if analysis_state.cancelled:
            return None
        
        # åˆ›å»ºå–æ¶ˆæ£€æŸ¥å™¨å‡½æ•°
        def cancel_checker():
            return analysis_state.cancelled
        
        result = await orchestrator.run_analysis(user_query, cancel_checker)
        
        # æ£€æŸ¥å–æ¶ˆçŠ¶æ€
        if analysis_state.cancelled:
            return None
        
        return result
        
    except Exception as e:
        # æ£€æŸ¥æ˜¯å¦æ˜¯å–æ¶ˆå¯¼è‡´çš„å¼‚å¸¸
        if analysis_state.cancelled:
            return None
        raise


def stop_analysis():
    """åœæ­¢æ­£åœ¨è¿è¡Œçš„åˆ†æ"""
    st.session_state.analysis_cancelled = True
    st.session_state.analysis_running = False
    
    # è®¾ç½®çŠ¶æ€å¯¹è±¡çš„å–æ¶ˆæ ‡å¿—
    analysis_state_obj = st.session_state.get('analysis_state_obj')
    if analysis_state_obj:
        analysis_state_obj.cancelled = True
        analysis_state_obj.running = False


def main():
    """ä¸»ç•Œé¢ - è¶…ç´§å‡‘è®¾è®¡ï¼Œç”¨æˆ·å¿«é€Ÿçœ‹åˆ°æŠ¥å‘Š"""
    # åŠ è½½æ ·å¼
    load_page_styles()
    
    # æ˜¾ç¤ºä¸“ä¸šæŠ¬å¤´
    try:
        st.markdown(create_header_html(), unsafe_allow_html=True)
    except:
        st.title("ğŸ›ï¸ AIå®éªŒå®¤ - TradingAgents")
    
    # æ ¸å¿ƒåŠŸèƒ½åŒºåŸŸ - å·¦å³å¸ƒå±€ï¼Œå‡å°‘æ»šåŠ¨
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # å®æ—¶åˆ†æåŒºåŸŸï¼ˆç´§å‡‘ç‰ˆï¼‰
        st.markdown("### ğŸ” å®æ—¶åˆ†æ")
        show_real_time_analysis()
        
        # å†å²ä¼šè¯ç®¡ç†ï¼ˆç´§å‡‘ç‰ˆï¼‰
        st.markdown("### ğŸ“š å†å²ä¼šè¯")
        show_history_management()
    
    with col2:
        # å¯¼å‡ºé€‰é¡¹ï¼ˆç´§å‡‘ç‰ˆï¼‰
        st.markdown("### ğŸ“¤ å¯¼å‡ºæŠ¥å‘Š")
        show_export_options()
        
        # ç³»ç»ŸçŠ¶æ€ï¼ˆè¶…ç´§å‡‘ç‰ˆï¼‰
        env_status = "âœ…" if Path(".env").exists() else "âŒ"
        mcp_status = "âœ…" if Path("mcp_config.json").exists() else "âŒ"
        
        st.markdown(f"**ç³»ç»ŸçŠ¶æ€:** ç¯å¢ƒ {env_status} | MCP {mcp_status}")
    
    # åˆ†æç»“æœå±•ç¤º - æ”¾åœ¨æœ€å‰é¢ï¼Œç”¨æˆ·ä¸ç”¨æ»šåŠ¨å°±èƒ½çœ‹åˆ°
    st.markdown("---")
    st.markdown("### ğŸ“ˆ åˆ†æç»“æœ")
    show_analysis_results()


if __name__ == "__main__":
    main()
