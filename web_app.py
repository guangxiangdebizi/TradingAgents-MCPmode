#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TradingAgents-MCPmode Webå‰ç«¯
å›½é‡‘è¯åˆ¸äººå·¥æ™ºèƒ½å®éªŒå®¤ - ä¸“ä¸šä¸€ä½“åŒ–äº¤æ˜“åˆ†æå¹³å°
"""

import streamlit as st
import os
import sys
import json
import asyncio
import threading
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥æ ·å¼åŠ è½½å™¨
try:
    from src.web.css_loader import (
        load_financial_css, inject_custom_html, create_header_html,
        create_metric_card_html, create_status_indicator_html,
        create_section_card_html, create_workflow_stage_html,
        apply_button_style
    )
except ImportError as e:
    st.error(f"æ— æ³•å¯¼å…¥CSSæ ·å¼æ¨¡å—: {e}")

# å¯¼å…¥å·¥ä½œæµç¨‹ç¼–æ’å™¨
try:
    from src.workflow_orchestrator import WorkflowOrchestrator
except ImportError as e:
    WorkflowOrchestrator = None
    st.error(f"æ— æ³•å¯¼å…¥WorkflowOrchestrator: {e}")

# å¯¼å…¥å¯¼å‡ºå·¥å…·
try:
    from src.dumptools.json_to_markdown import JSONToMarkdownConverter
    from src.dumptools.md2pdf import MarkdownToPDFConverter 
    from src.dumptools.md2docx import MarkdownToDocxConverter
except ImportError as e:
    st.error(f"æ— æ³•å¯¼å…¥å¯¼å‡ºå·¥å…·: {e}")
    JSONToMarkdownConverter = None
    MarkdownToPDFConverter = None
    MarkdownToDocxConverter = None

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="å›½é‡‘è¯åˆ¸AIå®éªŒå®¤ - TradingAgents",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "orchestrator" not in st.session_state:
    st.session_state.orchestrator = None
if "analysis_running" not in st.session_state:
    st.session_state.analysis_running = False
if "selected_session_file" not in st.session_state:
    st.session_state.selected_session_file = None
if "current_session_data" not in st.session_state:
    st.session_state.current_session_data = None
if "analysis_status" not in st.session_state:
    st.session_state.analysis_status = ""
if "analysis_progress" not in st.session_state:
    st.session_state.analysis_progress = 0
if "analysis_completed" not in st.session_state:
    st.session_state.analysis_completed = False
if "analysis_result" not in st.session_state:
    st.session_state.analysis_result = None


def load_page_styles():
    """åŠ è½½é¡µé¢æ ·å¼"""
    # åŠ è½½è‡ªå®šä¹‰CSS
    load_financial_css()
    # éšè—Streamlité»˜è®¤å…ƒç´ 
    inject_custom_html()
    # åº”ç”¨æŒ‰é’®æ ·å¼
    apply_button_style()


def show_system_overview():
    """ç³»ç»Ÿæ¦‚è§ˆåŒºåŸŸ"""
    # è·å–ç³»ç»Ÿç»Ÿè®¡æ•°æ®
    dump_dir = Path("src/dump")
    session_count = len(list(dump_dir.glob("session_*.json"))) if dump_dir.exists() else 0
    
    # åˆ›å»ºæŒ‡æ ‡ç½‘æ ¼
    metrics_html = f"""
    <div class="metric-grid">
        {create_metric_card_html("æ™ºèƒ½ä½“æ•°é‡", "15", "åˆ†å¸ƒå¼åˆ†æ")}
        {create_metric_card_html("åˆ†æç»´åº¦", "7", "å…¨æ–¹ä½è¦†ç›–")}
        {create_metric_card_html("è¾©è®ºæœºåˆ¶", "2å±‚", "çœ‹æ¶¨/çœ‹è·Œ+é£é™©")}
        {create_metric_card_html("å¸‚åœºæ”¯æŒ", "3ä¸ª", "Aè‚¡/æ¸¯è‚¡/ç¾è‚¡")}
        {create_metric_card_html("å†å²ä¼šè¯", str(session_count), "å¯æŸ¥çœ‹å’Œå¯¼å‡º")}
        {create_metric_card_html("å¯¼å‡ºæ ¼å¼", "3ç§", "MD/PDF/DOCX")}
    </div>
    """
    
    st.markdown(metrics_html, unsafe_allow_html=True)


def show_workflow_diagram():
    """å·¥ä½œæµç¨‹å›¾"""
    workflow_html = f"""
    {create_section_card_html("ğŸ”„ æ™ºèƒ½ä½“å·¥ä½œæµç¨‹", f"""
        {create_workflow_stage_html("é˜¶æ®µ1: åˆ†æå¸ˆå›¢é˜Ÿ", [
            "ğŸ¢ å…¬å¸æ¦‚è¿°", "ğŸ“ˆ å¸‚åœºæŠ€æœ¯", "ğŸ˜Š å¸‚åœºæƒ…ç»ª",
            "ğŸ“° æ–°é—»ä¿¡æ¯", "ğŸ“‹ åŸºæœ¬é¢", "ğŸ‘¥ è‚¡ä¸œç»“æ„", "ğŸ­ äº§å“åˆ†æ"
        ])}
        {create_workflow_stage_html("é˜¶æ®µ2: ä¸€å±‚è¾©è®º", [
            "ğŸ‚ çœ‹æ¶¨ç ”ç©¶å‘˜", "ğŸ» çœ‹è·Œç ”ç©¶å‘˜"
        ])}
        {create_workflow_stage_html("é˜¶æ®µ3: ç®¡ç†å±‚å†³ç­–", [
            "ğŸ¯ ç ”ç©¶ç»ç†", "ğŸ’° äº¤æ˜“å‘˜"
        ])}
        {create_workflow_stage_html("é˜¶æ®µ4: é£é™©ç®¡ç†", [
            "âš¡ æ¿€è¿›é£é™©", "ğŸ›¡ï¸ ä¿å®ˆé£é™©", "âš–ï¸ ä¸­æ€§é£é™©", "ğŸ¯ é£é™©ç»ç†"
        ])}
    """, "ğŸ”„")}
    """
    
    st.markdown(workflow_html, unsafe_allow_html=True)


def show_real_time_analysis():
    """å®æ—¶åˆ†ææ¨¡å—"""
    analysis_html = f"""
    {create_section_card_html("ğŸ” å®æ—¶åˆ†æ", """
        <p>åœ¨ä¸‹æ–¹è¾“å…¥æ‚¨çš„æŸ¥è¯¢ï¼Œç³»ç»Ÿå°†è°ƒç”¨15ä¸ªä¸“ä¸šæ™ºèƒ½ä½“è¿›è¡Œå…¨æ–¹ä½åˆ†æ</p>
    """, "ğŸ”")}
    """
    
    st.markdown(analysis_html, unsafe_allow_html=True)
    
    # æ£€æŸ¥WorkflowOrchestratoræ˜¯å¦å¯ç”¨
    if WorkflowOrchestrator is None:
        st.error("ğŸ˜± æ— æ³•åŠ è½½WorkflowOrchestratorï¼Œè¯·æ£€æŸ¥åç«¯é…ç½®")
        return
    
    # åˆ†æè¾“å…¥
    query = st.text_area(
        "è¯·è¾“å…¥æ‚¨çš„åˆ†ææŸ¥è¯¢",
        placeholder="ä¾‹å¦‚ï¼šç»™æˆ‘åˆ†æä¸€ä¸‹600833å§\nä¾‹å¦‚ï¼šåˆ†æè‹¹æœå…¬å¸(AAPL)çš„æŠ•èµ„ä»·å€¼",
        height=100,
        key="analysis_query"
    )
    
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col1:
        if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", disabled=st.session_state.analysis_running):
            if query:
                start_analysis(query)
            else:
                st.error("è¯·è¾“å…¥åˆ†ææŸ¥è¯¢")
    
    with col2:
        if st.button("â¹ï¸ åœæ­¢åˆ†æ", disabled=not st.session_state.analysis_running):
            st.session_state.analysis_running = False
            st.session_state.analysis_status = "å·²åœæ­¢"
            st.info("åˆ†æå·²åœæ­¢")
            st.rerun()
    
    with col3:
        if st.button("ğŸ”„ é‡ç½®çŠ¶æ€"):
            reset_analysis_state()
            st.rerun()
    
    # æ˜¾ç¤ºåˆ†æçŠ¶æ€
    if st.session_state.analysis_running or st.session_state.analysis_completed:
        status = st.session_state.get('analysis_status', 'æ­£åœ¨åˆå§‹åŒ–...')
        progress = st.session_state.get('analysis_progress', 0)
        
        # ä½¿ç”¨HTMLåˆ›å»ºæ›´ç¾è§‚çš„çŠ¶æ€æ˜¾ç¤º
        if st.session_state.analysis_running:
            status_html = create_status_indicator_html('running', status)
        elif st.session_state.analysis_completed:
            status_html = create_status_indicator_html('completed', "åˆ†æå®Œæˆ")
        else:
            status_html = create_status_indicator_html('idle', "ç³»ç»Ÿç©ºé—²")
        
        st.markdown(status_html, unsafe_allow_html=True)
        
        # è¿›åº¦æ¡
        st.progress(progress / 100.0)
        
        # å¦‚æœåˆ†æå®Œæˆä¸”æœ‰ç»“æœ
        if st.session_state.analysis_completed and st.session_state.analysis_result:
            result = st.session_state.analysis_result
            if isinstance(result, dict):
                # æ˜¾ç¤ºæ‰§è¡Œç»Ÿè®¡
                mcp_calls = len(result.get('mcp_tool_calls', []))
                agent_history = result.get('agent_execution_history', [])
                agent_executions = len(agent_history)
                mcp_enabled_agents = len([h for h in agent_history if h.get("mcp_used", False)])
                
                stats_html = f"""
                <div class="metric-grid">
                    {create_metric_card_html("æ™ºèƒ½ä½“æ‰§è¡Œ", str(agent_executions))}
                    {create_metric_card_html("MCPè°ƒç”¨", str(mcp_calls))}
                    {create_metric_card_html("å¯ç”¨MCP", f"{mcp_enabled_agents}/{agent_executions}")}
                </div>
                """
                st.markdown(stats_html, unsafe_allow_html=True)


def show_history_management():
    """å†å²ä¼šè¯ç®¡ç†"""
    history_html = f"""
    {create_section_card_html("ğŸ“š å†å²ä¼šè¯", """
        <p>é€‰æ‹©ã€åŠ è½½å’Œå¯¼å‡ºå†å²åˆ†æä¼šè¯</p>
    """, "ğŸ“š")}
    """
    
    st.markdown(history_html, unsafe_allow_html=True)
    
    # è·å–æ‰€æœ‰JSONæ–‡ä»¶
    dump_dir = Path("src/dump")
    if not dump_dir.exists():
        st.warning("âŒ dumpç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œåˆ†æç”Ÿæˆå†å²æ•°æ®")
        return
    
    json_files = list(dump_dir.glob("session_*.json"))
    if not json_files:
        st.info("ğŸ“­ æš‚æ— å†å²åˆ†ææ•°æ®")
        return
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
    json_files = sorted(json_files, key=lambda f: f.stat().st_mtime, reverse=True)
    
    # æ˜¾ç¤ºæœ€è¿‘çš„3ä¸ªä¼šè¯ä½œä¸ºå¿«é€Ÿè®¿é—®
    col1, col2, col3 = st.columns(3)
    
    for idx, json_file in enumerate(json_files[:3]):
        with [col1, col2, col3][idx]:
            file_time = datetime.fromtimestamp(json_file.stat().st_mtime)
            
            with st.container():
                st.markdown(f"""
                <div class="session-card" onclick="load_session('{json_file}')">
                    <div class="session-title">{json_file.name}</div>
                    <div class="session-meta">{file_time.strftime('%m-%d %H:%M')}</div>
                </div>
                """, unsafe_allow_html=True)
                
                if st.button(f"ğŸ“– åŠ è½½", key=f"load_{idx}"):
                    load_session_data(str(json_file))
    
    # å®Œæ•´æ–‡ä»¶é€‰æ‹©å™¨
    if len(json_files) > 3:
        st.markdown("#### ğŸ“‹ æ‰€æœ‰å†å²ä¼šè¯")
        
        file_options = []
        for json_file in json_files:
            file_time = datetime.fromtimestamp(json_file.stat().st_mtime)
            file_size = json_file.stat().st_size
            file_options.append(f"{json_file.name} ({file_time.strftime('%Y-%m-%d %H:%M:%S')}, {file_size}B)")
        
        selected_index = st.selectbox(
            "é€‰æ‹©å†å²ä¼šè¯",
            range(len(file_options)),
            format_func=lambda i: file_options[i],
            key="full_history_selector"
        )
        
        if st.button("ğŸ“– åŠ è½½é€‰ä¸­ä¼šè¯"):
            load_session_data(str(json_files[selected_index]))


def show_export_options():
    """å¯¼å‡ºé€‰é¡¹"""
    if not st.session_state.current_session_data or not st.session_state.selected_session_file:
        st.info("è¯·å…ˆåŠ è½½å†å²ä¼šè¯æ•°æ®")
        return
    
    export_html = f"""
    {create_section_card_html("ğŸ“¤ å¯¼å‡ºé€‰é¡¹", """
        <p>å°†å½“å‰åŠ è½½çš„ä¼šè¯å¯¼å‡ºä¸ºä¸åŒæ ¼å¼çš„æŠ¥å‘Š</p>
    """, "ğŸ“¤")}
    """
    
    st.markdown(export_html, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“„ å¯¼å‡ºMarkdown", use_container_width=True):
            export_to_markdown()
    
    with col2:
        if st.button("ğŸ“„ å¯¼å‡ºPDF", use_container_width=True):
            export_to_pdf()
    
    with col3:
        if st.button("ğŸ“„ å¯¼å‡ºWord", use_container_width=True):
            export_to_docx()


def show_analysis_results():
    """åˆ†æç»“æœå±•ç¤º"""
    if not st.session_state.current_session_data:
        st.info("è¯·å…ˆè¿è¡Œåˆ†ææˆ–åŠ è½½å†å²ä¼šè¯æŸ¥çœ‹ç»“æœ")
        return
    
    results_html = f"""
    {create_section_card_html("ğŸ“ˆ åˆ†æç»“æœ", """
        <p>å½“å‰ä¼šè¯çš„è¯¦ç»†æ™ºèƒ½ä½“åˆ†æç»“æœ</p>
    """, "ğŸ“ˆ")}
    """
    
    st.markdown(results_html, unsafe_allow_html=True)
    
    data = st.session_state.current_session_data
    
    # æ˜¾ç¤ºä¼šè¯åŸºæœ¬ä¿¡æ¯
    info_col1, info_col2, info_col3 = st.columns(3)
    with info_col1:
        st.metric("ä¼šè¯ID", data.get('session_id', 'N/A'))
    with info_col2:
        st.metric("çŠ¶æ€", data.get('status', 'N/A'))
    with info_col3:
        completed_agents = len([agent for agent in data.get('agents', []) if agent.get('status') == 'completed'])
        st.metric("å®Œæˆæ™ºèƒ½ä½“", f"{completed_agents}/{len(data.get('agents', []))}")
    
    # æ˜¾ç¤ºç”¨æˆ·æŸ¥è¯¢
    if data.get('user_query'):
        st.markdown("**ğŸ” åˆ†ææŸ¥è¯¢:**")
        st.info(data['user_query'])
    
    # æ™ºèƒ½ä½“ç»“æœæ ‡ç­¾é¡µ
    if data.get('agents'):
        completed_agents = [agent for agent in data['agents'] if agent.get('status') == 'completed']
        
        if completed_agents:
            # æŒ‰æ™ºèƒ½ä½“ç±»å‹åˆ†ç»„
            agent_groups = {
                "ğŸ“Š åˆ†æå¸ˆå›¢é˜Ÿ": ['company_overview_analyst', 'market_analyst', 'sentiment_analyst', 
                            'news_analyst', 'fundamentals_analyst', 'shareholder_analyst', 'product_analyst'],
                "ğŸ”„ çœ‹æ¶¨çœ‹è·Œè¾©è®º": ['bull_researcher', 'bear_researcher'],
                "ğŸ‘” ç ”ç©¶ä¸äº¤æ˜“": ['research_manager', 'trader'],
                "âš–ï¸ é£é™©ç®¡ç†": ['aggressive_risk_analyst', 'safe_risk_analyst', 'neutral_risk_analyst', 'risk_manager']
            }
            
            group_tabs = st.tabs(list(agent_groups.keys()))
            
            for tab_idx, (group_name, agent_names) in enumerate(agent_groups.items()):
                with group_tabs[tab_idx]:
                    group_agents = [agent for agent in completed_agents if agent.get('agent_name') in agent_names]
                    
                    if group_agents:
                        for agent in group_agents:
                            show_agent_result(agent)
                    else:
                        st.info(f"{group_name.split(' ', 1)[1]}æš‚æ— å®Œæˆçš„åˆ†æç»“æœ")
        else:
            st.info("è¯¥ä¼šè¯ä¸­æš‚æ— å®Œæˆçš„æ™ºèƒ½ä½“åˆ†æç»“æœ")
    else:
        st.info("è¯¥ä¼šè¯ä¸­æš‚æ— æ™ºèƒ½ä½“æ•°æ®")


def show_agent_result(agent: Dict[str, Any]):
    """æ˜¾ç¤ºå•ä¸ªæ™ºèƒ½ä½“ç»“æœ"""
    agent_name = agent.get('agent_name', 'Unknown')
    
    # æ™ºèƒ½ä½“åç§°æ˜ å°„
    name_mapping = {
        'company_overview_analyst': 'ğŸ¢ å…¬å¸æ¦‚è¿°åˆ†æå¸ˆ',
        'market_analyst': 'ğŸ“ˆ å¸‚åœºåˆ†æå¸ˆ',
        'sentiment_analyst': 'ğŸ˜Š æƒ…ç»ªåˆ†æå¸ˆ',
        'news_analyst': 'ğŸ“° æ–°é—»åˆ†æå¸ˆ',
        'fundamentals_analyst': 'ğŸ“‹ åŸºæœ¬é¢åˆ†æå¸ˆ',
        'shareholder_analyst': 'ğŸ‘¥ è‚¡ä¸œåˆ†æå¸ˆ',
        'product_analyst': 'ğŸ­ äº§å“åˆ†æå¸ˆ',
        'bull_researcher': 'ğŸ‚ çœ‹æ¶¨ç ”ç©¶å‘˜',
        'bear_researcher': 'ğŸ» çœ‹è·Œç ”ç©¶å‘˜',
        'research_manager': 'ğŸ¯ ç ”ç©¶ç»ç†',
        'trader': 'ğŸ’° äº¤æ˜“å‘˜',
        'aggressive_risk_analyst': 'âš¡ æ¿€è¿›é£é™©åˆ†æå¸ˆ',
        'safe_risk_analyst': 'ğŸ›¡ï¸ ä¿å®ˆé£é™©åˆ†æå¸ˆ',
        'neutral_risk_analyst': 'âš–ï¸ ä¸­æ€§é£é™©åˆ†æå¸ˆ',
        'risk_manager': 'ğŸ¯ é£é™©ç»ç†'
    }
    
    display_name = name_mapping.get(agent_name, f"ğŸ¤– {agent_name}")
    
    with st.expander(display_name, expanded=False):
        if agent.get('result'):
            st.markdown(agent['result'])
        else:
            st.info("è¯¥æ™ºèƒ½ä½“æš‚æ— åˆ†æç»“æœ")


# å¯¼å‡ºåŠŸèƒ½
def export_to_markdown():
    """å¯¼å‡ºMarkdown"""
    if not JSONToMarkdownConverter:
        st.error("âŒ Markdownå¯¼å‡ºå™¨ä¸å¯ç”¨")
        return
    
    try:
        converter = JSONToMarkdownConverter("src/dump")
        result = converter.convert_json_to_markdown(st.session_state.selected_session_file)
        if result and os.path.exists(result):
            st.success(f"âœ… Markdownå¯¼å‡ºæˆåŠŸ: {result}")
            
            # æä¾›ä¸‹è½½é“¾æ¥
            with open(result, 'r', encoding='utf-8') as f:
                content = f.read()
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½Markdownæ–‡ä»¶",
                data=content,
                file_name=f"{Path(result).name}",
                mime="text/markdown"
            )
        else:
            st.error("âŒ Markdownå¯¼å‡ºå¤±è´¥")
    except Exception as e:
        st.error(f"âŒ å¯¼å‡ºé”™è¯¯: {str(e)}")


def export_to_pdf():
    """å¯¼å‡ºPDF"""
    if not MarkdownToPDFConverter:
        st.error("âŒ PDFå¯¼å‡ºå™¨ä¸å¯ç”¨")
        return
    
    try:
        converter = MarkdownToPDFConverter("src/dump")
        result = converter.convert_json_to_pdf_via_markdown(st.session_state.selected_session_file)
        if result and os.path.exists(result):
            st.success(f"âœ… PDFå¯¼å‡ºæˆåŠŸ: {result}")
            
            # æä¾›ä¸‹è½½é“¾æ¥
            with open(result, 'rb') as f:
                content = f.read()
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½PDFæ–‡ä»¶",
                data=content,
                file_name=f"{Path(result).name}",
                mime="application/pdf"
            )
        else:
            st.error("âŒ PDFå¯¼å‡ºå¤±è´¥")
    except Exception as e:
        st.error(f"âŒ PDFå¯¼å‡ºé”™è¯¯: {str(e)}")


def export_to_docx():
    """å¯¼å‡ºWordæ–‡æ¡£"""
    if not MarkdownToDocxConverter:
        st.error("âŒ DOCXå¯¼å‡ºå™¨ä¸å¯ç”¨")
        return
    
    try:
        converter = MarkdownToDocxConverter("src/dump")
        result = converter.convert_json_to_docx_via_markdown(st.session_state.selected_session_file)
        if result and os.path.exists(result):
            st.success(f"âœ… DOCXå¯¼å‡ºæˆåŠŸ: {result}")
            
            # æä¾›ä¸‹è½½é“¾æ¥
            with open(result, 'rb') as f:
                content = f.read()
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½Wordæ–‡ä»¶",
                data=content,
                file_name=f"{Path(result).name}",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
        else:
            st.error("âŒ DOCXå¯¼å‡ºå¤±è´¥")
    except Exception as e:
        st.error(f"âŒ DOCXå¯¼å‡ºé”™è¯¯: {str(e)}")


def load_session_data(json_file_path: str):
    """åŠ è½½ä¼šè¯æ•°æ®"""
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            session_data = json.load(f)
        st.session_state.selected_session_file = json_file_path
        st.session_state.current_session_data = session_data
        st.success(f"âœ… å·²åŠ è½½ä¼šè¯: {Path(json_file_path).name}")
        st.rerun()
    except Exception as e:
        st.error(f"âŒ åŠ è½½å¤±è´¥: {str(e)}")


def start_analysis(query: str):
    """å¼€å§‹åˆ†æ"""
    # é‡ç½®çŠ¶æ€
    st.session_state.analysis_running = True
    st.session_state.analysis_completed = False
    st.session_state.analysis_status = "æ­£åœ¨åˆå§‹åŒ–..."
    st.session_state.analysis_progress = 0
    st.session_state.analysis_result = None
    
    # è¿è¡Œåˆ†æ
    run_analysis_sync(query)


def run_analysis_sync(query: str):
    """åŒæ­¥è¿è¡Œåˆ†æ"""
    try:
        load_dotenv()
        
        st.session_state.analysis_status = "æ­£åœ¨åˆå§‹åŒ–å·¥ä½œæµç¼–æ’å™¨..."
        st.session_state.analysis_progress = 10
        
        # ä½¿ç”¨asyncio.runè¿è¡Œå¼‚æ­¥å‡½æ•°
        result = asyncio.run(run_single_analysis_async(query))
        
        # åˆ†ææˆåŠŸ
        st.session_state.analysis_result = result
        st.session_state.analysis_completed = True
        st.session_state.analysis_status = "âœ… åˆ†æå®Œæˆï¼"
        st.session_state.analysis_progress = 100
        st.session_state.analysis_running = False
        
        st.success("ğŸ‰ åˆ†æå®Œæˆï¼è¯·æŸ¥çœ‹ä¸‹æ–¹ç»“æœã€‚")
        st.rerun()
            
    except Exception as e:
        error_msg = str(e)
        st.session_state.analysis_status = f"âŒ åˆ†æé”™è¯¯: {error_msg}"
        st.session_state.analysis_running = False
        st.session_state.analysis_completed = False
        
        st.error(f"åˆ†æå¤±è´¥: {error_msg}")
        st.rerun()


async def run_single_analysis_async(user_query: str) -> Optional[dict]:
    """è¿è¡Œå•æ¬¡åˆ†æ"""
    orchestrator = WorkflowOrchestrator("mcp_config.json")
    
    try:
        st.session_state.analysis_status = "æ­£åœ¨åˆå§‹åŒ–å·¥ä½œæµç¼–æ’å™¨..."
        st.session_state.analysis_progress = 10
        await orchestrator.initialize()
        
        st.session_state.analysis_status = "æ­£åœ¨åŠ è½½é…ç½®ä¿¡æ¯..."
        st.session_state.analysis_progress = 20
        
        workflow_info = orchestrator.get_workflow_info()
        enabled_agents = orchestrator.get_enabled_agents()
        
        st.session_state.analysis_status = f"å¯ç”¨çš„æ™ºèƒ½ä½“: {len(enabled_agents)}ä¸ª"
        st.session_state.analysis_progress = 30
        
        st.session_state.analysis_status = f"æ­£åœ¨åˆ†æ: {user_query}"
        st.session_state.analysis_progress = 50
        
        result = await orchestrator.run_analysis(user_query)
        
        st.session_state.analysis_status = "æ­£åœ¨å¤„ç†ç»“æœ..."
        st.session_state.analysis_progress = 90
        
        # å°†ç»“æœåŠ è½½åˆ°ä¼šè¯çŠ¶æ€
        if result:
            st.session_state.current_session_data = result
        
        return result
        
    except Exception as e:
        st.session_state.analysis_status = f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}"
        raise
    finally:
        await orchestrator.close()


def reset_analysis_state():
    """é‡ç½®åˆ†æçŠ¶æ€"""
    st.session_state.analysis_running = False
    st.session_state.analysis_completed = False
    st.session_state.analysis_status = ""
    st.session_state.analysis_progress = 0
    st.session_state.analysis_result = None


def main():
    """ä¸»ç•Œé¢"""
    # åŠ è½½æ ·å¼
    load_page_styles()
    
    # æ˜¾ç¤ºä¸“ä¸šæŠ¬å¤´
    st.markdown(create_header_html(), unsafe_allow_html=True)
    
    # ç³»ç»Ÿæ¦‚è§ˆ
    show_system_overview()
    
    # å·¥ä½œæµç¨‹å›¾
    show_workflow_diagram()
    
    st.markdown("---")
    
    # å®æ—¶åˆ†æåŒºåŸŸ
    show_real_time_analysis()
    
    st.markdown("---")
    
    # å†å²ä¼šè¯ç®¡ç†
    show_history_management()
    
    st.markdown("---")
    
    # å¯¼å‡ºé€‰é¡¹
    show_export_options()
    
    st.markdown("---")
    
    # åˆ†æç»“æœå±•ç¤º
    show_analysis_results()
    
    # åº•éƒ¨çŠ¶æ€ä¿¡æ¯
    st.markdown("---")
    
    # æ£€æŸ¥é…ç½®çŠ¶æ€
    env_status = "âœ…" if Path(".env").exists() else "âŒ"
    mcp_status = "âœ…" if Path("mcp_config.json").exists() else "âŒ"
    
    status_html = f"""
    <div style="text-align: center; color: var(--text-muted); font-size: 0.9rem; margin-top: 2rem;">
        <p>ç³»ç»ŸçŠ¶æ€: ç¯å¢ƒé…ç½® {env_status} | MCPé…ç½® {mcp_status} | ğŸ›ï¸ å›½é‡‘è¯åˆ¸äººå·¥æ™ºèƒ½å®éªŒå®¤</p>
    </div>
    """
    
    st.markdown(status_html, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
