#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
JSON to Markdown Converter
ä¸“é—¨ä¸ºdumpæ–‡ä»¶å¤¹ä¸‹çš„JSONæ–‡æ¡£å¯¼å‡ºä¸ºMarkdownçš„å·¥å…·
"""

import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional
import re


class JSONToMarkdownConverter:
    """JSONè½¬Markdownè½¬æ¢å™¨"""
    
    def __init__(self, dump_dir: str = "src/dump", include_mcp_calls: bool = False):
        """åˆå§‹åŒ–è½¬æ¢å™¨
        
        Args:
            dump_dir: dumpæ–‡ä»¶å¤¹è·¯å¾„
            include_mcp_calls: æ˜¯å¦åœ¨Markdownä¸­åŒ…å«MCPå·¥å…·è°ƒç”¨ä¿¡æ¯ï¼ˆé»˜è®¤å…³é—­ï¼‰
        """
        self.dump_dir = Path(dump_dir)
        self.output_dir = Path("markdown_reports")
        self.include_mcp_calls = include_mcp_calls
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir.mkdir(exist_ok=True)
    
    def convert_json_to_markdown(self, json_file_path: str) -> Optional[str]:
        """å°†JSONæ–‡ä»¶è½¬æ¢ä¸ºMarkdown
        
        Args:
            json_file_path: JSONæ–‡ä»¶è·¯å¾„
            
        Returns:
            ç”Ÿæˆçš„Markdownæ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # è¯»å–JSONæ–‡ä»¶
            with open(json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # ç”ŸæˆMarkdownå†…å®¹
            markdown_content = self._generate_markdown(data)
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            json_filename = Path(json_file_path).stem
            output_file = self.output_dir / f"{json_filename}.md"
            
            # å†™å…¥Markdownæ–‡ä»¶
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(markdown_content)
            
            print(f"âœ… MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")
            return str(output_file)
            
        except Exception as e:
            print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
            return None
    
    def _normalize_result_headers(self, result_text: str) -> str:
        """æ ‡å‡†åŒ– result ä¸­çš„æ ‡é¢˜æ ¼å¼ï¼š
        - æ™ºèƒ½è¯†åˆ« AI æ–‡æœ¬ä¸­çš„æ ‡é¢˜å±‚çº§ï¼Œä½¿å…¶æœ€é«˜çº§åˆ«è°ƒæ•´ä¸ºäºŒçº§æ ‡é¢˜ï¼ˆ##ï¼‰
        - åŒæ—¶ä¿ç•™ç›¸å¯¹å±‚çº§å…³ç³»ï¼ˆæ•´ä½“å¹³ç§»ï¼‰ï¼Œæœ€å¤§ä¸è¶…è¿‡å…­çº§
        ä¾‹å¦‚ï¼šè‹¥æ–‡æœ¬å†…æœ€é¡¶å±‚ä¸º `#`ï¼Œåˆ™æ•´ä½“ +1ï¼›è‹¥æœ€é¡¶å±‚ä¸º `###`ï¼Œåˆ™æ•´ä½“ -1ï¼Œä½¿å…¶é¡¶å±‚å˜ä¸º `##`
        """
        if not result_text:
            return result_text
        
        lines = result_text.split('\n')
        normalized_lines = []

        # æ”¶é›†æ‰€æœ‰æ ‡é¢˜çº§åˆ«ï¼ˆ1-6çº§ï¼‰
        heading_levels = []
        heading_matches = []
        for line in lines:
            m = re.match(r'^(#{1,6})\s*(.+?)\s*$', line)
            heading_matches.append(m)
            if m:
                level = len(m.group(1))
                heading_levels.append(level)
        
        if not heading_levels:
            return result_text
        
        min_level = min(heading_levels)
        offset = 2 - min_level  # è®©æœ€é«˜çº§åˆ«è°ƒæ•´ä¸ºäºŒçº§æ ‡é¢˜
        
        for idx, line in enumerate(lines):
            m = heading_matches[idx]
            if m:
                old_level = len(m.group(1))
                text = m.group(2).strip()
                new_level = old_level + offset
                if new_level < 2:
                    new_level = 2
                if new_level > 6:
                    new_level = 6
                normalized_lines.append(f"{'#' * new_level} {text}")
            else:
                normalized_lines.append(line)
        
        return '\n'.join(normalized_lines)

    def _remove_emojis(self, text: str) -> str:
        """ç§»é™¤æ–‡æœ¬ä¸­çš„æ‰€æœ‰ emoji/å˜ä½“/ä¸å¯è§ç©ºç™½ ç­‰ç¬¦å·ã€‚"""
        emoji_pattern = re.compile(
            r"[\u2300-\u23FF\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002600-\U000027BF\U0001F900-\U0001F9FF\U0001F018-\U0001F270]",
            re.UNICODE,
        )
        cleaned = emoji_pattern.sub('', text)
        # å»é™¤å˜ä½“é€‰æ‹©ç¬¦ä¸é›¶å®½/ä¸å¯æ–­ç©ºæ ¼ç­‰
        cleaned = re.sub(r"[\uFE0E\uFE0F\u200B\u200C\u200D\u2060\ufeff\u00A0\u202F]", '', cleaned)
        return cleaned

    def _strip_heading_prefix(self, title: str) -> str:
        """å»é™¤æ ‡é¢˜ä¸­å·²æœ‰çš„ç¼–å·/åºå·/ä¸­æ–‡åºå·åŠæ”¶å°¾æ ‡ç‚¹ï¼Œå¹¶æ¸…ç†å‰å¯¼æ‚é¡¹å­—ç¬¦ã€‚
        å¤„ç†åœºæ™¯ï¼š
        - 15.2  äºŒã€ æ ‡é¢˜
        - ä¸€ã€ æ ‡é¢˜ / åä¸€ã€ æ ‡é¢˜
        - 1) æ ‡é¢˜ / 1.2.3. æ ‡é¢˜
        - å‰å¯¼å­˜åœ¨ä¸å¯è§å­—ç¬¦æˆ–å˜ä½“é€‰æ‹©ç¬¦ï¼ˆå¦‚ \uFE0Fï¼‰
        """
        t = title.strip()
        # å»æ‰ä¸å¯è§/å˜ä½“å­—ç¬¦
        t = re.sub(r'[\u200b\u200c\u200d\u2060\ufeff\uFE0E\uFE0F]', '', t)
        # å¾ªç¯æ¸…ç†ï¼Œç›´åˆ°æ— æ³•å†åŒ¹é…ï¼ˆæ”¯æŒâ€œå›¾æ ‡ + ä¸­æ–‡åºå· + é¡¿å·/é€—å· + ç©ºæ ¼â€çš„ç»„åˆï¼‰
        while True:
            before = t
            # å…ˆå¼ºåˆ¶å»å‰ç½®æ‰€æœ‰ emoji/ç¬¦å·ï¼ˆåŒ…å«é—¹é’Ÿ/é“ƒé“›ç­‰ U+23xxï¼‰
            t = self._remove_emojis(t)
            # æ•°å­—åˆ†çº§ï¼š1. / 1.2 / 1.2.3. / 1ï¼‰/ 1) / 15.3 ï¸ äºŒã€
            t = re.sub(r'^[\s\t]*\d+(?:\s*[\.ï¼]\s*\d+)*\s*[\.)ã€ï¼]?[\s\uFE0E\uFE0F\u200B\u200C\u200D\u2060\ufeff\u00A0\u202F]*', '', t)
            # ä¸­æ–‡åºå·ï¼šä¸€ã€ äºŒã€ åä¸€ã€ ç­‰
            t = re.sub(r'^[\s\t]*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ã€‡]+[ã€\.ï¼)]\s*', '', t)
            # å…¶ä»–å¸¸è§å‰å¯¼æ ‡ç‚¹/ç¬¦å·
            t = re.sub(r'^[\s\t]*[\-â€¢*Â·]+\s*', '', t)
            t = re.sub(r'^[\s\t]*[,:ï¼šã€ï¼Œ\.ï¼\)\(ï¼ˆï¼‰]+\s*', '', t)
            if t == before:
                break
        # å…œåº•ï¼šåˆ é™¤èµ·å§‹å¤„ç”±â€œæ•°å­—/ä¸­æ–‡æ•°å­—/åˆ†éš”ç¬¦/ä¸å¯è§å­—ç¬¦â€ç»„æˆçš„è¿ç»­å‰ç¼€
        t = re.sub(r'^[\s\uFE0E\uFE0F\u200B\u200C\u200D\u2060\ufeff\u00A0\u202F0-9ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ã€‡\-â€¢*Â·,:ï¼šã€ï¼Œ\.ï¼\)\(ï¼ˆï¼‰]+', '', t)
        return t.strip()

    def _number_all_headings(self, markdown_text: str) -> str:
        """ä¸ºæ‰€æœ‰ Markdown æ ‡é¢˜æ·»åŠ åˆ†çº§ç¼–å·ï¼š
        # 1.
        ## 1.1
        ### 1.1.1
        #### 1.1.1.1
        ç¼–å·æŒ‰å‡ºç°é¡ºåºè‡ªåŠ¨é€’å¢ï¼›éæ ‡é¢˜è¡Œä¸å¤„ç†ã€‚
        """
        lines = markdown_text.split('\n')
        counters = [0, 0, 0, 0, 0, 0]  # å¯¹åº”1~6çº§
        result_lines: List[str] = []
        for line in lines:
            m = re.match(r'^(#{1,6})\s*(.+?)\s*$', line)
            if not m:
                result_lines.append(line)
                continue
            level = len(m.group(1))
            text = m.group(2)
            # å»é™¤emojiä¸åŸæœ‰ç¼–å·ï¼ˆå¾ªç¯ç›´åˆ°ç¨³å®šï¼Œå¤„ç†éšè—å­—ç¬¦å¯¼è‡´çš„ä¸€æ¬¡ä¸åŒ¹é…ï¼‰
            prev = None
            while prev != text:
                prev = text
                text = self._remove_emojis(text)
                text = self._strip_heading_prefix(text)
            # è§„èŒƒå¤šä½™ç©ºç™½ï¼šå°†è¿ç»­ç©ºç™½å‹ç¼©ä¸ºå•ä¸ªç©ºæ ¼ï¼ŒåŒæ—¶å»é¦–å°¾ç©ºç™½
            text = re.sub(r'\s+', ' ', text).strip()
            # å»é™¤æ ‡é¢˜ä¸­çš„ Markdown å¼ºè°ƒæ ‡è®°ï¼ˆç²—ä½“/æ–œä½“ï¼‰
            text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)
            text = re.sub(r'__(.+?)__', r'\1', text)
            text = re.sub(r'(?<!\*)\*(?!\*)(.+?)(?<!\*)\*(?!\*)', r'\1', text)
            text = re.sub(r'(?<!_)_(?!_)(.+?)(?<!_)_(?!_)', r'\1', text)
            # å…œåº•ï¼šæ¸…ç†æ®‹ç•™çš„ * / _ / `ï¼ˆä¾‹å¦‚ä¸æˆå¯¹çš„ ** æˆ–å•ä¸ª *ï¼‰
            text = re.sub(r'[\*`_]+', '', text)
            # ç»´æŠ¤è®¡æ•°å™¨
            idx = level - 1
            counters[idx] += 1
            for j in range(idx + 1, 6):
                counters[j] = 0
            # ç”Ÿæˆç¼–å·å‰ç¼€
            nums = [str(counters[i]) for i in range(level) if counters[i] > 0]
            number_prefix = '.'.join(nums)
            # ç¡®ä¿ç¼–å·ä¸æ ‡é¢˜æ–‡æœ¬ä¹‹é—´æ°å¥½ä¸€ä¸ªç©ºæ ¼
            new_title = f"{number_prefix} {text}"
            result_lines.append(f"{'#' * level} {new_title}")
        return '\n'.join(result_lines)

    def _extract_single_h1_title(self, text: str):
        """å¦‚æœæ–‡æœ¬ä¸­æ°å¥½æœ‰ä¸€ä¸ªä¸€çº§æ ‡é¢˜ï¼Œè¿”å›(æ ‡é¢˜æ–‡æœ¬, å»é™¤è¯¥æ ‡é¢˜åçš„æ­£æ–‡)ã€‚å¦åˆ™è¿”å›(None, åŸæ–‡)ã€‚"""
        lines = text.split('\n')
        h1_indices = [i for i, line in enumerate(lines) if re.match(r'^#\s+.+', line.strip())]
        if len(h1_indices) != 1:
            return None, text
        idx = h1_indices[0]
        title_line = lines[idx]
        m = re.match(r'^#\s+(.+)$', title_line.strip())
        title_text = m.group(1).strip() if m else title_line.lstrip('#').strip()
        # æ¸…ç†emojiå’Œæ—§ç¼–å·
        title_text = self._strip_heading_prefix(self._remove_emojis(title_text))
        # å»æ‰è¯¥è¡Œ
        remaining = lines[:idx] + lines[idx+1:]
        return title_text, '\n'.join(remaining)

    def _promote_headings(self, text: str, levels: int = 1) -> str:
        """å°†æ‰€æœ‰Markdownæ ‡é¢˜æ•´ä½“ä¸Šæï¼ˆçº§åˆ«æ•°å­—å‡å°ï¼‰ï¼Œæœ€å°ä¸ä½äº1ã€‚"""
        def repl(match):
            hashes = match.group(1)
            heading_text = match.group(2)
            old = len(hashes)
            new = max(1, old - levels)
            return f"{'#' * new} {heading_text.strip()}"
        return re.sub(r'^(#{1,6})\s*(.+)$', repl, text, flags=re.MULTILINE)
    
    def _get_agent_mcp_calls(self, agent_name: str, mcp_calls: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è·å–æŒ‡å®šagentçš„MCPè°ƒç”¨è®°å½•"""
        return [call for call in mcp_calls if call.get('agent_name') == agent_name]
    
    def _generate_mcp_calls_section(self, agent_name: str, mcp_calls: List[Dict[str, Any]]) -> str:
        """ç”ŸæˆæŒ‡å®šagentçš„MCPè°ƒç”¨ä¿¡æ¯"""
        lines = []
        if mcp_calls:
            lines.append(f"#### ğŸ”§ MCPå·¥å…·è°ƒç”¨ (å…±{len(mcp_calls)}æ¬¡)")
            lines.append("")
            for i, call in enumerate(mcp_calls, 1):
                lines.append(f"**è°ƒç”¨ {i}**:")
                tool_name = call.get('tool_name', 'N/A')
                timestamp = call.get('timestamp', 'N/A')
                lines.append(f"- å·¥å…·: {tool_name}")
                lines.append(f"- æ—¶é—´: {timestamp}")
                if call.get('tool_result'):
                    lines.append(f"- ç»“æœ: {call['tool_result'][:100]}..." if len(call.get('tool_result', '')) > 100 else f"- ç»“æœ: {call.get('tool_result', '')}")
                lines.append("")
            lines.append("---")
            lines.append("")
        return '\n'.join(lines)
    
    def _generate_markdown(self, data: Dict[str, Any]) -> str:
        """ç”ŸæˆMarkdownå†…å®¹"""
        md_lines = []
        
        # ===== å°é¢é¡µ =====
        user_query = data.get('user_query', '')
        cover_title = user_query if user_query else f"äº¤æ˜“åˆ†ææŠ¥å‘Š - {data.get('session_id', 'Unknown')}"
        # å°é¢ä¸ä½¿ç”¨æ ‡é¢˜çº§åˆ«ï¼Œæ”¹ä¸ºåŠ ç²—å¼ºè°ƒ
        md_lines.append(f"**{cover_title}**")
        md_lines.append("")
        md_lines.append(f"**ç ”ç©¶é—®é¢˜ï¼š** {user_query if user_query else 'N/A'}")
        md_lines.append("")
        md_lines.append("ç”±å›½é‡‘è¯åˆ¸äººå·¥æ™ºèƒ½å®éªŒå®¤çš„ Agent è‡ªåŠ¨ç”Ÿæˆ")
        md_lines.append("")
        md_lines.append(f"**æäº¤æ—¥æœŸï¼š** {datetime.now().strftime('%Y å¹´ %m æœˆ %d æ—¥')}")
        md_lines.append("")
        md_lines.append("---")
        md_lines.append("")
        
        # æ™ºèƒ½ä½“åˆ†æç»“æœ - åªå¯¼å‡ºå·²å®Œæˆçš„æ™ºèƒ½ä½“çš„ç»“æœ
        if 'agents' in data and data['agents']:
            # è¿‡æ»¤å‡ºstatusä¸ºcompletedçš„æ™ºèƒ½ä½“
            completed_agents = [agent for agent in data['agents'] if agent.get('status') == 'completed']
            
            if completed_agents:
                # è·å–MCPè°ƒç”¨æ•°æ®ï¼ˆå¯å¼€å…³ï¼Œé»˜è®¤ä¸åŒ…å«ï¼‰
                mcp_calls = data.get('mcp_calls', []) if self.include_mcp_calls else []
                
                for agent in completed_agents:
                    agent_name = agent.get('agent_name', 'Unknown Agent')
                    
                    # æ ¹æ®æ™ºèƒ½ä½“ç±»å‹è®¾ç½®æ›´å¥½çš„æ ‡é¢˜
                    title_mapping = {
                        'company_overview_analyst': 'å…¬å¸æ¦‚è¿°åˆ†æ',
                        'market_analyst': 'å¸‚åœºæŠ€æœ¯åˆ†æ',
                        'sentiment_analyst': 'å¸‚åœºæƒ…ç»ªåˆ†æ', 
                        'news_analyst': 'æ–°é—»ä¿¡æ¯åˆ†æ',
                        'fundamentals_analyst': 'åŸºæœ¬é¢åˆ†æ',
                        'shareholder_analyst': 'è‚¡ä¸œç»“æ„åˆ†æ',
                        'bull_researcher': 'çœ‹æ¶¨è§‚ç‚¹',
                        'bear_researcher': 'çœ‹è·Œè§‚ç‚¹',
                        # æ–°å¢ï¼šè‹±æ–‡è§’è‰²åˆ°ä¸­æ–‡æ˜ å°„ï¼ˆé¢†å¯¼å¯è¯»ï¼‰
                        'product_analyst': 'äº§å“åˆ†æ',
                        'research_manager': 'ç ”ç©¶ç»ç†',
                        'trader': 'äº¤æ˜“æ‰§è¡Œ',
                        'aggressive_risk_analyst': 'è¿›å–å‹é£é™©åˆ†æ',
                        'safe_risk_analyst': 'ç¨³å¥å‹é£é™©åˆ†æ',
                        'risk_manager': 'é£é™©ç®¡ç†'
                    }
                    
                    section_title = title_mapping.get(agent_name, agent_name)
                    clean_section_title = self._strip_heading_prefix(self._remove_emojis(section_title))

                    # ç‰¹ä¾‹ï¼šå¦‚æœAIå†…å®¹ä¸­æ°å¥½å­˜åœ¨ä¸€ä¸ªä¸€çº§æ ‡é¢˜ï¼Œåˆ™ç”¨å®ƒæ›¿æ¢Agentçš„å¤§æ ‡é¢˜
                    agent_result_text = agent.get('result') or ''
                    extracted_title, rest_text = self._extract_single_h1_title(agent_result_text)
                    if extracted_title:
                        md_lines.append(f"# {extracted_title}")
                        md_lines.append("")
                        # ä¸å†ä¸Šæå‡ä½™å†…å®¹çš„æ ‡é¢˜ï¼Œä¿æŒå…¶æœ€é«˜çº§åˆ«ä¸ºäºŒçº§ï¼ˆåç»­ç»Ÿä¸€è§„èŒƒï¼‰
                        content_to_use = rest_text
                    else:
                        md_lines.append(f"# {clean_section_title} åˆ†æç»“æœ")
                        md_lines.append("")
                        content_to_use = agent_result_text
                    
                    # æ˜¾ç¤ºè¯¥agentçš„MCPè°ƒç”¨ä¿¡æ¯ï¼ˆæ ¹æ®å¼€å…³å†³å®šæ˜¯å¦å±•ç¤ºï¼‰
                    if self.include_mcp_calls:
                        agent_mcp_calls = self._get_agent_mcp_calls(agent_name, mcp_calls)
                        if agent_mcp_calls:
                            mcp_section = self._generate_mcp_calls_section(agent_name, agent_mcp_calls)
                            md_lines.append(mcp_section)
                    
                    # å¤„ç†å¹¶å¯¼å‡ºåˆ†æç»“æœ
                    if content_to_use:
                        # æ— è®ºæ˜¯å¦æ›¿æ¢æ ‡é¢˜ï¼Œç»Ÿä¸€å°†æœ€é«˜çº§æ ‡é¢˜è§„èŒƒä¸ºäºŒçº§
                        normalized_result = self._normalize_result_headers(content_to_use)
                        md_lines.append(normalized_result)
                        md_lines.append("")
                        md_lines.append("---")
                        md_lines.append("")
        
        # é˜¶æ®µä¿¡æ¯
        if 'stages' in data and data['stages']:
            md_lines.append("## ğŸ“Š æ‰§è¡Œé˜¶æ®µ")
            md_lines.append("")
            for i, stage in enumerate(data['stages'], 1):
                md_lines.append(f"### é˜¶æ®µ {i}")
                md_lines.append("")
                md_lines.append(f"**å†…å®¹**: {stage}")
                md_lines.append("")
        

        
        # é”™è¯¯ä¿¡æ¯
        if 'errors' in data and data['errors']:
            md_lines.append("## âŒ é”™è¯¯ä¿¡æ¯")
            md_lines.append("")
            for error in data['errors']:
                md_lines.append(f"- {error}")
            md_lines.append("")
        
        # è­¦å‘Šä¿¡æ¯
        if 'warnings' in data and data['warnings']:
            md_lines.append("## âš ï¸ è­¦å‘Šä¿¡æ¯")
            md_lines.append("")
            for warning in data['warnings']:
                md_lines.append(f"- {warning}")
            md_lines.append("")
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        md_lines.append("---")
        md_lines.append("")
        md_lines.append(f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")

        # åˆå¹¶ã€ç»Ÿä¸€ç¼–å·å¹¶ç§»é™¤æ‰€æœ‰emoji
        raw_markdown = "\n".join(md_lines)
        numbered_markdown = self._number_all_headings(raw_markdown)
        final_markdown = self._remove_emojis(numbered_markdown)
        return final_markdown
    
    def convert_latest_json(self) -> Optional[str]:
        """è½¬æ¢æœ€æ–°çš„JSONæ–‡ä»¶
        
        Returns:
            ç”Ÿæˆçš„Markdownæ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # æŸ¥æ‰¾dumpç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶
            json_files = list(self.dump_dir.glob("session_*.json"))
            
            if not json_files:
                print(f"âŒ åœ¨ {self.dump_dir} ç›®å½•ä¸‹æœªæ‰¾åˆ°JSONæ–‡ä»¶")
                return None
            
            # æ‰¾åˆ°æœ€æ–°çš„æ–‡ä»¶
            latest_json = max(json_files, key=lambda f: f.stat().st_mtime)
            print(f"ğŸ“„ æ‰¾åˆ°æœ€æ–°çš„JSONæ–‡ä»¶: {latest_json.name}")
            
            # è½¬æ¢ä¸ºMarkdown
            return self.convert_json_to_markdown(str(latest_json))
            
        except Exception as e:
            print(f"âŒ è½¬æ¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    def convert_all_json(self) -> List[str]:
        """è½¬æ¢æ‰€æœ‰JSONæ–‡ä»¶
        
        Returns:
            ç”Ÿæˆçš„Markdownæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            # æŸ¥æ‰¾dumpç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶
            json_files = list(self.dump_dir.glob("session_*.json"))
            
            if not json_files:
                print(f"âŒ åœ¨ {self.dump_dir} ç›®å½•ä¸‹æœªæ‰¾åˆ°JSONæ–‡ä»¶")
                return []
            
            results = []
            for json_file in json_files:
                print(f"ğŸ“„ è½¬æ¢æ–‡ä»¶: {json_file.name}")
                result = self.convert_json_to_markdown(str(json_file))
                if result:
                    results.append(result)
            
            return results
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡è½¬æ¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return []
    
    def list_available_json_files(self) -> List[str]:
        """åˆ—å‡ºå¯ç”¨çš„JSONæ–‡ä»¶
        
        Returns:
            JSONæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            json_files = list(self.dump_dir.glob("session_*.json"))
            return [str(f) for f in sorted(json_files, key=lambda f: f.stat().st_mtime, reverse=True)]
        except Exception as e:
            print(f"âŒ åˆ—å‡ºæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return []


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œå·¥å…·"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="JSON to Markdown Converter - å°†dumpæ–‡ä»¶å¤¹ä¸‹çš„JSONæ–‡æ¡£è½¬æ¢ä¸ºMarkdown"
    )
    parser.add_argument("-f", "--file", help="æŒ‡å®šè¦è½¬æ¢çš„JSONæ–‡ä»¶è·¯å¾„")
    parser.add_argument("-l", "--latest", action="store_true", help="è½¬æ¢æœ€æ–°çš„JSONæ–‡ä»¶")
    parser.add_argument("-a", "--all", action="store_true", help="è½¬æ¢æ‰€æœ‰JSONæ–‡ä»¶")
    parser.add_argument("--list", action="store_true", help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„JSONæ–‡ä»¶")
    parser.add_argument("-d", "--dump-dir", default="src/dump", help="dumpæ–‡ä»¶å¤¹è·¯å¾„")
    parser.add_argument("--include-mcp", action="store_true", help="åœ¨Markdownä¸­åŒ…å«MCPå·¥å…·è°ƒç”¨ä¿¡æ¯ï¼ˆé»˜è®¤ä¸åŒ…å«ï¼‰")
    
    args = parser.parse_args()
    
    converter = JSONToMarkdownConverter(args.dump_dir, include_mcp_calls=args.include_mcp)
    
    if args.list:
        # åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ–‡ä»¶
        files = converter.list_available_json_files()
        if files:
            print("ğŸ“‹ å¯ç”¨çš„JSONæ–‡ä»¶:")
            for i, file_path in enumerate(files, 1):
                file_name = Path(file_path).name
                file_time = datetime.fromtimestamp(Path(file_path).stat().st_mtime)
                print(f"  {i}. {file_name} ({file_time.strftime('%Y-%m-%d %H:%M:%S')})")
        else:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•JSONæ–‡ä»¶")
    
    elif args.all:
        # è½¬æ¢æ‰€æœ‰æ–‡ä»¶
        results = converter.convert_all_json()
        if results:
            print(f"ğŸ‰ æ‰¹é‡è½¬æ¢å®Œæˆï¼Œå…±ç”Ÿæˆ {len(results)} ä¸ªMarkdownæ–‡ä»¶")
        else:
            print("âŒ æ‰¹é‡è½¬æ¢å¤±è´¥")
    
    elif args.latest:
        # è½¬æ¢æœ€æ–°æ–‡ä»¶
        result = converter.convert_latest_json()
        if result:
            print(f"ğŸ‰ è½¬æ¢å®Œæˆ: {result}")
    
    elif args.file:
        # è½¬æ¢æŒ‡å®šæ–‡ä»¶
        if os.path.exists(args.file):
            result = converter.convert_json_to_markdown(args.file)
            if result:
                print(f"ğŸ‰ è½¬æ¢å®Œæˆ: {result}")
        else:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.file}")
    
    else:
        # é»˜è®¤è½¬æ¢æœ€æ–°æ–‡ä»¶
        result = converter.convert_latest_json()
        if result:
            print(f"ğŸ‰ è½¬æ¢å®Œæˆ: {result}")


if __name__ == "__main__":
    main()
